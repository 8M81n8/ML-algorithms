{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_VS_dog_classification",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrishabh145/ML-algorithms/blob/master/cat_VS_dog_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VVz6DiluPN",
        "colab_type": "text"
      },
      "source": [
        "**PART 1: Importing data from kaggle and setting up the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4CyhJLhoth3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqjRL4MnqyIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload kaggle API key file\n",
        "# Generate this file from Kaggle account\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBk_xOAuFQLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make directory named kaggle and copy kaggle.json file there.\n",
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Change the permissions of the file.\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvC-JmJMFfOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can check if everything's okay by running this command.\n",
        "! kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSqHx51Pxgnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading the dataset\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28F88q5SaMm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipping the files into two folders\n",
        "!unzip train.zip\n",
        "!unzip test.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK2JiHg33Jiv",
        "colab_type": "text"
      },
      "source": [
        "**PART 2: Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnpMTdXWzD9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2  # to resize the image\n",
        "import numpy as np \n",
        "import os   #to work with the directories\n",
        "from random import shuffle  #to shuffle the data\n",
        "from tqdm import tqdm   #for visualising looping\n",
        "\n",
        "# Location of extracted data\n",
        "TRAIN_DIR = '/content/train'\n",
        "TEST_DIR = '/content/test'\n",
        "\n",
        "IMG_SIZE = 50   # making all size 50x50\n",
        "LR = 1e-3  # Learning Rate\n",
        "\n",
        "# Saving a model name for future reference\n",
        "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic-video')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF2JMknzduXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to manually one hot encode tha cat or dog label from image file names\n",
        "def label_img(img):\n",
        "  # dog.93.png will be split and 'dog' will be used as word label\n",
        "  word_label = img.split('.')[-3]\n",
        "  if word_label == 'cat': return[1,0]\n",
        "  elif word_label == 'dog': return[0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6sl8FqIgM1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to process images to create training data\n",
        "def create_train_data():\n",
        "  training_data = []\n",
        "  for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "    label = label_img(img)  # getting the label of the image\n",
        "    path = os.path.join(TRAIN_DIR, img) # getting the full parth of the image file\n",
        "    \n",
        "    # Converting images into grayscale and then resizing them into 50x50\n",
        "    img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE) ) \n",
        "    training_data.append([np.array(img), np.array(label)]) #converting image to numpy array and saving\n",
        "\n",
        "  shuffle(training_data)\n",
        "  np.save('training_data.npy', training_data) #saving processed data to use in the model\n",
        "  return training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNErVhiwl1yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# processing images to create testing_data\n",
        "# prediction file of testing_data is to be returned\n",
        "def process_test_data():\n",
        "  testing_data = []\n",
        "  for img in tqdm(os.listdir(TEST_DIR)):\n",
        "    path = os.path.join(TEST_DIR, img) # getting the full parth of the image file\n",
        "    img_num = img.split('.')[0]\n",
        "\n",
        "    # Converting images into grayscale and then resizing them into 50x50\n",
        "    img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE),(IMG_SIZE,IMG_SIZE))\n",
        "    testing_data.append([np.array(img), img_num]) #converting image to numpy array and saving\n",
        "\n",
        "  np.save('test_data.npy',testing_data) #saving processed data to use in the model\n",
        "  return testing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qNoE8zbqBz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = create_train_data() # This will create train data\n",
        "# If you already have train data:\n",
        "#train_data = np.load('training_data.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y8dtu2u3q31",
        "colab_type": "text"
      },
      "source": [
        "**PART 3: Model initialisation, building and training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGxN4M5g6Xi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the tensorflow version of colab notebook to tf 1.x\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Installing tflearn\n",
        "! pip install -q tflearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGwxeYWn8BG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To rerun the code or training, uncomment the below code.\n",
        "# This will reset the graph generated in the last training session\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm1pE-mdi1X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "\n",
        "convnet = input_data(shape = [None, IMG_SIZE, IMG_SIZE, 1], name = 'input')\n",
        "\n",
        "# 6 layers of covnvnet followed by 1 layer of fully connected layers\n",
        "convnet = conv_2d(convnet, 32, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet, 128, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet, 128, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = conv_2d(convnet, 32, 2, activation = 'relu')\n",
        "convnet = max_pool_2d(convnet,2)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation = 'relu')\n",
        "convnet = dropout(convnet,0.8)\n",
        "\n",
        "convnet = fully_connected(convnet, 2, activation = 'softmax')\n",
        "convnet = regression(convnet, optimizer = 'adam', learning_rate = LR, loss = 'categorical_crossentropy', name = 'targets')\n",
        "\n",
        "model =tflearn.DNN(convnet, tensorboard_dir = 'log')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_oidmtqkLZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if a partially trained model is available in the direcetory, loading that checkpoint file to continue training\n",
        "# the model further\n",
        "if os.path.exists('{},meta'.format(MODEL_NAME)):\n",
        "  model.load(MODEL_NAME)\n",
        "  print('model loaded!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bHJ4LGkK5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seperating train and test data\n",
        "train = train_data[:-500]\n",
        "test = train_data[-500:]\n",
        "\n",
        "# seperating the features and labels for TRAIN data\n",
        "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "Y = [i[1] for i in train]\n",
        "\n",
        "# seperating the features and labels for TEST data\n",
        "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "test_y = [i[1] for i in test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rNXKgrz4ofx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model and validating on holdout set (test set)\n",
        "model.fit({'input':X}, {'targets':Y}, n_epoch = 12, validation_set = ({'input':test_x},{'targets':test_y}), snapshot_step = 500, show_metric = True, run_id = MODEL_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUYO7wCEqoHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model for future predictions or retraining the model\n",
        "model.save(MODEL_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LEypE9_oCK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualise contents of the model and training on tensorboard\n",
        "#%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJYRzBLM3XJj",
        "colab_type": "text"
      },
      "source": [
        "**PART 4: Predictions and visualisations on unlabeled data using trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWdvgFRJ3Wkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# if you dont already have this file yet\n",
        "test_data = process_test_data()\n",
        "# if you already have it\n",
        "#test_data = np.load('test_data.npy')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "# run first 12 test images though the model and plot on a figure along with\n",
        "# their classification labels to check if the model is working properly and accurately\n",
        "for num, data in enumerate(test_data[:12]):\n",
        "  # cat : [1,0]\n",
        "  # dog : [0,1]\n",
        "  \n",
        "  img_num = data[1] #image label number\n",
        "  img_data = data[0]  #image in the form of numpy array\n",
        "\n",
        "  y = fig.add_subplot(3,4,num+1) \n",
        "  orig = img_data\n",
        "  data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
        "\n",
        "  model_out = model.predict([data])[0]  # predicting on test images\n",
        "  \n",
        "  # setting label to be displayed in the graph\n",
        "  if np.argmax(model_out) == 1: str_label = 'Dog'\n",
        "  else: str_label = 'Cat'\n",
        "\n",
        "  y.imshow(orig, cmap = 'gray') #displaying image in grayscale\n",
        "  plt.title(str_label)\n",
        "  y.axes.get_xaxis().set_visible(False)\n",
        "  y.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84F2eZF080Gd",
        "colab_type": "text"
      },
      "source": [
        "**PART 5: Creating a kaggle submission file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5OraVCt4kyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a new empty csv file\n",
        "with open('submission-file.csv','w') as f:\n",
        "  f.write('id,label\\n') #It will over-write the whole file with the above data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k869ihnxADYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# writing the predictions in the created csv file in append mode\n",
        "with open('submission-file.csv','a') as f:\n",
        "  for data in tqdm(test_data):\n",
        "    img_num = data[1]  #image label number\n",
        "    img_data = data[0]  #image in the form of numpy array\n",
        "    orig = img_data\n",
        "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
        "    model_out = model.predict([data])[0]  # predicting on test images\n",
        "    # model_out will be in the form :\n",
        "    # [ 0.25, 0.75 ]\n",
        "    f.write('{},{}\\n'.format(img_num, model_out[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_l2ezvyAEto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f submission-file.csv -m \"My first Kaggle Submission\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmUTouHaAESs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}